{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b7069a1",
   "metadata": {},
   "source": [
    "# L25: Name generation with GPT-2\n",
    "\n",
    "Steps:\n",
    "1. Install the dependencies\n",
    "2. Load the imports\n",
    "3. Define the model and tokenizer\n",
    "4. Tokenize all the names\n",
    "5. Prepare the data for training\n",
    "6. Set up the training arguments\n",
    "7. Train the model\n",
    "8. Generate new names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe63fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3341c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the imports\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorForLanguageModeling, AutoModelForCausalLM\n",
    "from transformers import Trainer, TrainingArguments, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a1514d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'emma'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "dataset = load_dataset('text', data_files='names.txt')\n",
    "\n",
    "# look at first item\n",
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6978a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose model and tokenizer\n",
    "model_name = 'distilgpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, pad_token=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db109df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gar', 'rett', '<|endoftext|>']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function to tokenize a name\n",
    "def tokenize_name(name):\n",
    "    tokens = tokenizer(\n",
    "        name['text'] + tokenizer.eos_token,\n",
    "    )\n",
    "\n",
    "    return tokens\n",
    "\n",
    "tokenized_name = tokenize_name({'text' : 'garrett'})\n",
    "token_id_list = tokenized_name['input_ids']\n",
    "token_list = tokenizer.convert_ids_to_tokens(token_id_list)\n",
    "\n",
    "token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7a10788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 32033\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5413a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 32033/32033 [00:03<00:00, 9705.74 examples/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 32033\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_names = dataset['train'].map(\n",
    "    tokenize_name,\n",
    "    batched=False,\n",
    "    remove_columns=['text']\n",
    ")\n",
    "\n",
    "tokenized_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d58c99a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset for training\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a39268c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50258, 768)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up training arguments\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5da3737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 01:18, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=3.1282080078125, metrics={'train_runtime': 79.8535, 'train_samples_per_second': 10.018, 'train_steps_per_second': 1.252, 'total_flos': 926786912256.0, 'train_loss': 3.1282080078125, 'epoch': 0.024968789013732832})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='name-gpt',\n",
    "    per_device_train_batch_size=8,\n",
    "    max_steps=100,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_names,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc15d033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('name-gpt/tokenizer_config.json',\n",
       " 'name-gpt/special_tokens_map.json',\n",
       " 'name-gpt/vocab.json',\n",
       " 'name-gpt/merges.txt',\n",
       " 'name-gpt/added_tokens.json',\n",
       " 'name-gpt/tokenizer.json')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the trained model\n",
    "trainer.save_model('name-gpt')\n",
    "tokenizer.save_pretrained('name-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa9ae8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jimah\n",
      "jimian\n",
      "jimyn\n",
      "jimley\n",
      "jimiah\n",
      "jimiah\n",
      "jimie\n",
      "jimah\n",
      "jimay\n",
      "jimiah\n"
     ]
    }
   ],
   "source": [
    "# generate new names\n",
    "generator = pipeline(\n",
    "    'text-generation',\n",
    "    model='name-gpt',\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generated_names = generator(\n",
    "    'jim',\n",
    "    max_length=20,\n",
    "    truncation=True,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=10,\n",
    "    top_k=50,\n",
    "    top_p=0.95\n",
    ")\n",
    "\n",
    "for name in generated_names:\n",
    "    print(name['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff80e06f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
